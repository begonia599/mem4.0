"""
ä¼šè¯ç®¡ç†æ¨¡å— - æ§åˆ¶å¯¹è¯å’Œè®°å¿†çš„æ•´ä½“æµç¨‹
"""
import threading
import queue
import time
import os
from .memory_manager import MemoryManager
from .response_manager import ResponseManager
from vector.embedder import MemoryEmbedder
from vector.retriever import MemoryRetriever

class Session:
    def __init__(self, llm_client, config):
        """
        åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯å®ä¾‹
            config: é…ç½®å¯¹è±¡
        """
        self.llm_client = llm_client
        self.config = config
        
        # åˆ›å»ºé˜Ÿåˆ—ç”¨äºçº¿ç¨‹é—´é€šä¿¡
        self.memory_queue = queue.Queue()  # å‘é€åˆ°è®°å¿†ç®¡ç†å™¨çš„é˜Ÿåˆ—
        self.response_queue = queue.Queue()  # ä»è®°å¿†ç®¡ç†å™¨æ¥æ”¶çš„é˜Ÿåˆ—
        
        # åˆå§‹åŒ–å‘é‡åŒ–ç»„ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.embedder = None
        self.retriever = None
        if hasattr(config, 'VECTOR_SEARCH_ENABLED') and config.VECTOR_SEARCH_ENABLED:
            try:
                self.embedder = MemoryEmbedder(config)
                self.embedder.load_or_create_index()
                self.retriever = MemoryRetriever(self.embedder)
                print("å‘é‡æ£€ç´¢åŠŸèƒ½å·²åˆå§‹åŒ–")
            except Exception as e:
                print(f"å‘é‡æ£€ç´¢åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆ›å»ºç®¡ç†å™¨
        self.memory_manager = MemoryManager(llm_client, self.memory_queue, self.response_queue, self.embedder)
        self.response_manager = ResponseManager(llm_client, config)
        
        # ä¼šè¯çŠ¶æ€
        self.system_message = None
        self.model = config.DEFAULT_MODEL
        self.enable_memory = config.ENABLE_MEMORY
        self.auto_memory = False
        self.running = False
        self.memories = []
        
        # çº¿ç¨‹
        self.memory_thread = None
        
    def start(self):
        """å¯åŠ¨ä¼šè¯ï¼ŒåŒ…æ‹¬è®°å¿†å¤„ç†çº¿ç¨‹"""
        if self.running:
            return
            
        self.running = True
        self.memory_thread = threading.Thread(target=self._memory_processor)
        self.memory_thread.daemon = True  # å®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»çº¿ç¨‹ç»“æŸæ—¶è‡ªåŠ¨é€€å‡º
        self.memory_thread.start()
        
    def stop(self):
        """åœæ­¢ä¼šè¯åŠç›¸å…³çº¿ç¨‹"""
        self.running = False
        if self.memory_thread:
            self.memory_thread.join(timeout=1.0)
    
    def process_message(self, user_message):
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œç”Ÿæˆå›å¤
        
        Args:
            user_message (str): ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            
        Returns:
            str: åŠ©æ‰‹çš„å›å¤
        """
        # è·å–ä¸Šä¸‹æ–‡å†å²ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        history_messages = None
        if self.enable_memory:
            history_messages = self.response_manager.get_history_messages()
        
        # æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆå¦‚æœå¯ç”¨å‘é‡æ£€ç´¢ï¼‰
        memory_context = ""
        if self.retriever and self.config.VECTOR_SEARCH_ENABLED:
            try:
                print("ğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³è®°å¿†...")
                results, scores = self.memory_manager.query_memories(
                    user_message, 
                    self.retriever, 
                    self.config.TOP_K
                )
                
                if results:
                    memory_context = self.retriever.format_search_results(
                        user_message, results, scores
                    )
                    print(f"ğŸ” æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†")
                    # å¯ä»¥é€‰æ‹©æ€§åœ°æ˜¾ç¤ºæ£€ç´¢åˆ°çš„éƒ¨åˆ†è®°å¿†
                    if len(results) > 0:
                        print(f"ğŸ“š ç›¸å…³åº¦æœ€é«˜çš„è®°å¿†: {results[0][:50]}...")
                else:
                    print("ğŸ“­ æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
            except Exception as e:
                print(f"â— è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
        
        # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡åˆ°ç”¨æˆ·æ¶ˆæ¯
        enhanced_message = user_message
        if memory_context:
            enhanced_message = memory_context + "\n\n" + user_message
        
        # ç”Ÿæˆå›å¤
        response = self.llm_client.ask(
            prompt=enhanced_message,
            model=self.model,
            system_message=self.system_message,
            history_messages=history_messages
        )
        
        # ä¿å­˜å¯¹è¯è®°å½•ï¼ˆä¿å­˜åŸå§‹ç”¨æˆ·æ¶ˆæ¯ï¼Œè€Œéå¢å¼ºåçš„æ¶ˆæ¯ï¼‰
        self.response_manager.add_exchange(user_message, response)
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨è®°å¿†ï¼Œå°†æ¶ˆæ¯å‘é€åˆ°è®°å¿†å¤„ç†é˜Ÿåˆ—
        if self.auto_memory:
            self.memory_queue.put({
                "type": "analyze",
                "content": user_message,
                "timestamp": time.time()
            })
        
        return response
    
    def _memory_processor(self):
        """è®°å¿†å¤„ç†çº¿ç¨‹çš„ä¸»å¾ªç¯"""
        while self.running:
            try:
                # éé˜»å¡æ–¹å¼è·å–ä»»åŠ¡ï¼Œè¶…æ—¶åæ£€æŸ¥runningçŠ¶æ€
                try:
                    task = self.memory_queue.get(timeout=0.5)
                except queue.Empty:
                    continue
                
                # å¤„ç†ä¸åŒç±»å‹çš„è®°å¿†ä»»åŠ¡
                if task["type"] == "analyze":
                    # åˆ†æå†…å®¹æ˜¯å¦éœ€è¦è®°å¿†
                    print("\nğŸ”„ åå°æ­£åœ¨åˆ†æå¯¹è¯å†…å®¹...")
                    if self.memory_manager.should_remember(task["content"]):
                        print("ğŸ§  æ£€æµ‹åˆ°é‡è¦ä¿¡æ¯ï¼Œå¼€å§‹æå–è®°å¿†...")
                        success = self.memory_manager.extract_memory(task["content"])
                        if success:
                            print("âœ… è®°å¿†æå–å’Œå­˜å‚¨å®Œæˆ")
                        else:
                            print("âš ï¸ è®°å¿†æå–æµç¨‹å®Œæˆï¼Œä½†æœªæå–åˆ°æœ‰æ•ˆè®°å¿†")
                    else:
                        print("ğŸ“ åˆ†æå®Œæˆï¼Œæ­¤å†…å®¹æ— éœ€è®°å¿†")
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.memory_queue.task_done()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªè®°å¿†ç®¡ç†å™¨çš„å“åº”
                while not self.response_queue.empty():
                    response = self.response_queue.get()
                    if response["type"] == "memory":
                        self.memories.append(response["content"])
                        print(f"æ–°è®°å¿†å·²æ·»åŠ : {response['content']['content']}")
                    self.response_queue.task_done()
                    
            except Exception as e:
                print(f"è®°å¿†å¤„ç†çº¿ç¨‹é”™è¯¯: {e}")
                
    # ä¾¿æ·æ–¹æ³•
    def set_system_message(self, message):
        self.system_message = message
        
    def set_model(self, model):
        self.model = model
        
    def toggle_memory(self, enable):
        self.enable_memory = enable
        
    def toggle_auto_memory(self, enable):
        self.auto_memory = enable
        
    def get_memories(self):
        return self.memories
        
    def clear_history(self):
        self.response_manager.clear_history()
        
    def get_history(self, turns=None):
        return self.response_manager.get_history(turns)
        
    def save_history(self, filename):
        self.response_manager.save_history(filename)
        
    def load_history(self, filename):
        self.response_manager.load_history(filename)
        
    def toggle_vector_search(self, enable):
        """å¼€å…³å‘é‡æ£€ç´¢åŠŸèƒ½"""
        self.config.VECTOR_SEARCH_ENABLED = enable